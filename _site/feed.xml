<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-08-16T21:25:33+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Mijn familie</title><author><name>Jeroen Rijks</name></author><entry><title type="html">How to run scripts in AWS</title><link href="http://localhost:4000/2020/07/17/triggering-lambda-scripts.html" rel="alternate" type="text/html" title="How to run scripts in AWS" /><published>2020-07-17T05:30:00+01:00</published><updated>2020-07-17T05:30:00+01:00</updated><id>http://localhost:4000/2020/07/17/triggering-lambda%20scripts</id><content type="html" xml:base="http://localhost:4000/2020/07/17/triggering-lambda-scripts.html">&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;
&lt;p&gt;People often want to run a piece of code whenever a certain condition is met. The most intuitive method of doing this is using some kind of scheduler, which constantly checks whether the condition is met, and then decides whether the script should run or not. The example below will run the &lt;code class=&quot;highlighter-rouge&quot;&gt;runScript()&lt;/code&gt; method&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// really bad pseudocode

hour = Time.getHour()
if hour = 7
  runScript()
else
  wait for 1 hour
  go to top
end

def runScript
  script code here...
end

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, this code needs to run constantly throughout the day, to check whether it should run &lt;code class=&quot;highlighter-rouge&quot;&gt;runScript()&lt;/code&gt;. This is mildly annoying if it’s running on your local machine, since you need your computer to be on, and running the process at 7am. When you move this to the cloud, it becomes even more impractical, since you’re paying per minute of server time. This is especially annoying because most of this server-time is spent checking the time, instead of actually running the script. For a script that runs for a minute every day, you’d be overpaying for your server by a factor of &lt;code class=&quot;highlighter-rouge&quot;&gt;60 * 24 = 1440&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Note that this concept applies to any script that only runs when a condition is met - you’re not just paying for script run-time, but also to constantly check whether the condition is met.&lt;/p&gt;

&lt;h2 id=&quot;separating-condition-checking-from-script-running&quot;&gt;Separating condition-checking from script-running&lt;/h2&gt;

&lt;p&gt;AWS Lambda lets you run scripts using their “serverless” model, in which you supply the code, and they’ll run it by provisioning whatever server you want, until the script execution is finished. You only pay while your script is running. This only leaves a single challenge - how do you ensure that this script only runs when its condition is met? The solution depends on your implementation, and I’ll discuss two scenarios, in which the Lambda script is triggered at either a certain time, or using a webhook.&lt;/p&gt;

&lt;h2 id=&quot;time-trigger&quot;&gt;Time trigger&lt;/h2&gt;
&lt;p&gt;We’ll try to create a lambda function that says “Hello world”, and run it at midday every day.&lt;/p&gt;

&lt;h4 id=&quot;creating-the-lambda-function&quot;&gt;Creating the Lambda function&lt;/h4&gt;
&lt;p&gt;First, I’ll log into my AWS account, and head to the Lambdas dashboard.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;/assets/img/lambda_dashboard.png&quot; alt=&quot;Lambda dashboard&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I’ll choose to create a new lambda, and choose to run it in Python 3.8 (arbitrarily, because I’m just as bad at all programming languages).&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;/assets/img/new_lambda_function.png&quot; alt=&quot;Creating a new lambda function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This takes me to an in-browser editor, with the following code:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import json

def lambda_handler(event, context):
    # TODO implement
    return {
        'statusCode': 200,
        'body': json.dumps('Hello from Lambda!')
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When the lambda function is triggered, it will run the &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda_handler()&lt;/code&gt; event. For our purposes, I’ll change it to&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import json

def lambda_handler(event, context):
    run_script()
    return {
        'statusCode': 200,
        'body': json.dumps('Hello from Lambda!')
    }

def run_script():
    print(&quot;Hello world&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When this runs, I expect my Lambda function’s log to contain “Hello world”. To test this expectation, I pressed the “Test” button, which creates a new test event, simulating a JSON payload that gets passed into my function, under &lt;code class=&quot;highlighter-rouge&quot;&gt;context&lt;/code&gt;. I’m not using any external variables in my script, so I accept the default values, and create the test event.&lt;/p&gt;

&lt;p&gt;After saving, running this test event shows the JSON response, which shows that my &lt;code class=&quot;highlighter-rouge&quot;&gt;run_script()&lt;/code&gt; function ran. You’re now free to edit this, to do whatever you need it to do.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;/assets/img/execution_results.png&quot; alt=&quot;Test event results&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;triggering-the-lambda-function-at-midday&quot;&gt;Triggering the lambda function at midday&lt;/h4&gt;
&lt;p&gt;To avoid paying for a server to see if the time condition is met, we want to outsource this to a managed service - AWS CloudWatch. CloudWatch is usually used because it offers insights on resource usage, but we’ll use it because it also lets you send notifications (using AWS SNS) at customisable intervals, which is exactly what we need. We’ll create a Lambda-invoking notification in AWS SNS, and then a CloudWatch rule that sends this SNS notification.&lt;/p&gt;

&lt;p&gt;First, we go to the SNS Topics dashboard, and create a new Topic (notification type). The topic is really simple and doesn’t need anything other than a name (I’ve chosen &lt;code class=&quot;highlighter-rouge&quot;&gt;InvokeLambdaMidday&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Next, I head over to the CloudWatch rules dashboard, and create a new rule. I’ll select a scheduled rule for 12am every day. This is done using a cron expression, which follows the &lt;code class=&quot;highlighter-rouge&quot;&gt;minute hour day-of-month month day-of-week year&lt;/code&gt; format. For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;0 12 * * ? *&lt;/code&gt; means “Run at 12:00 every day”. Go to the &lt;a href=&quot;https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html&quot;&gt;AWS docs&lt;/a&gt; to learn more.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;/assets/img/new_rule.png&quot; alt=&quot;Cloudwatch rule&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;/assets/img/new_rule_2.png&quot; alt=&quot;Cloudwatch rule&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Going back to my Lambda function, I can now add a trigger, so that it is invoked every time the SNS topic sends a notification at midday. This trigger should provide the SNS topic with the appropriate permissions for invoking the Lambda function. Under the Lambda function’s permissions tab, its access policy should be set to something like:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Id&quot;: &quot;default&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Sid&quot;: &quot;lambda-e3f578a6-3dc2-4d88-b3d8-73fc8c80068a&quot;,
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Principal&quot;: {
        &quot;Service&quot;: &quot;sns.amazonaws.com&quot;
      },
      &quot;Action&quot;: &quot;lambda:InvokeFunction&quot;,
      &quot;Resource&quot;: &quot;arn:aws:lambda:eu-west-2:&amp;lt;my AWS account ID&amp;gt;:function:helloWorldAtMidday&quot;,
      &quot;Condition&quot;: {
        &quot;ArnLike&quot;: {
          &quot;AWS:SourceArn&quot;: &quot;arn:aws:sns:eu-west-2:&amp;lt;my AWS account ID&amp;gt;:InvokeMiddayLambda&quot;
        }
      }
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This essentially says that the &lt;code class=&quot;highlighter-rouge&quot;&gt;helloWorldAtMidday&lt;/code&gt; function may be invoked by SNS, if the SNS topic in question is called &lt;code class=&quot;highlighter-rouge&quot;&gt;InvokeMiddayLambda&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;/assets/img/add_trigger.png&quot; alt=&quot;Add trigger&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, to test this SNS-to-Lambda link, I’ll publish a message in the SNS topic manually. I’ll select the correct SNS topic, select publish message, and just chuck &lt;code class=&quot;highlighter-rouge&quot;&gt;asdf&lt;/code&gt; into the message body, because it won’t let me keep it blank. After publishing the message, I’ll head back over to the Lambda, and under the Monitoring tab, I can see that its most recent invocation was at the current time.&lt;/p&gt;

&lt;h2 id=&quot;webhook-trigger&quot;&gt;Webhook trigger&lt;/h2&gt;

&lt;p&gt;Triggering a Lambda function from within your code is very simple. AWS provide software development kits (SDKs) that allow you to manage AWS resources within your own codebase. For Python, the SDK is called &lt;code class=&quot;highlighter-rouge&quot;&gt;boto3&lt;/code&gt;, and its Lambda component can be imported using&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import boto3
client = boto3.client('lambda')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This client represents the internet-facing Lambda API, which you can send requests to using &lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/lambda.html#Lambda.Client.invoke&quot;&gt;this documentation&lt;/a&gt;. In our case, we want to invoke the Lambda function, so we would want something like this:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;response = client.invoke(
    FunctionName='helloWorldAtMidday',  # function name
    InvocationType='RequestResponse',  # `RequestResponse` waits for the lambda function's response, while `Event` is asynchronous.
    LogType='Tail', # Setting this to `Tail` would show the Lambda's logs in this codebase's own logs
    ClientContext='',  # We can leave this empty
    Payload=b'bytes'|file, # If your Lambda function takes arguments as input, then this is where you'd pass those in, as JSON. This will be passed into the function's lambda_handler as the `payload` argument
    Qualifier='string' # If you have multiple versions or aliases of your Lambda function, then you can specify them here. For simple Lambdas, don't bother
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;authentication&quot;&gt;Authentication&lt;/h4&gt;
&lt;p&gt;It wouldn’t be very secure if anybody can invoke your Lambda functions in AWS, so you’ll need to “authenticate” your server with AWS. This can be done by passing in AWS credentials into the server with the &lt;code class=&quot;highlighter-rouge&quot;&gt;AWS_ACCESS_KEY_ID&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt; environment variables, which will be automatically picked up by &lt;code class=&quot;highlighter-rouge&quot;&gt;boto3&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;It’s best practice to create a separate AWS IAM (identity and access management) user for your server, with minimal permissions assigned to it (including permission to invoke the Lambda function). An example would be&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Id&quot;: &quot;default&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Action&quot;: &quot;lambda:InvokeFunction&quot;,
      &quot;Resource&quot;: &quot;arn:aws:lambda:eu-west-2:&amp;lt;my AWS account ID&amp;gt;:function:helloWorldAtMidday&quot;,
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;implementation&quot;&gt;Implementation&lt;/h4&gt;
&lt;p&gt;To run this script as a response to a webhook, set up a webhook endpoint, which runs this code, and then, if necessary, returns a successful response if the Lambda has run successfully.&lt;/p&gt;</content><author><name>Jeroen Rijks</name></author><summary type="html">The problem People often want to run a piece of code whenever a certain condition is met. The most intuitive method of doing this is using some kind of scheduler, which constantly checks whether the condition is met, and then decides whether the script should run or not. The example below will run the runScript() method</summary></entry><entry><title type="html">CIDR notation</title><link href="http://localhost:4000/2020/06/14/cidr_notation.html" rel="alternate" type="text/html" title="CIDR notation" /><published>2020-06-14T15:00:13+01:00</published><updated>2020-06-14T15:00:13+01:00</updated><id>http://localhost:4000/2020/06/14/cidr_notation</id><content type="html" xml:base="http://localhost:4000/2020/06/14/cidr_notation.html">&lt;p&gt;When I started working at Transreport, I was working with existing infrastructure, which other people had set in place for me. This let me get by without exposing me to a huge gap in my knowledge - networks, and how they work.&lt;/p&gt;

&lt;p&gt;When creating VPCs in AWS, users need to input the VPC’s CIDR block, which is a range of IP addresses, expressed (for IPv4 IP addresses) as &lt;code class=&quot;highlighter-rouge&quot;&gt;a.b.c.d/x&lt;/code&gt;, where &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;d&lt;/code&gt; are integers between 0 and 255, and &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt; is an integer between 1 and 32. This is because IPv4 IP addresses can be written in binary as four 8-digit binary numbers: &lt;code class=&quot;highlighter-rouge&quot;&gt;aaaaaaaa.bbbbbbbb.cccccccc.dddddddd&lt;/code&gt;, with &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt; denoting how many of the 32 digits describe the network’s address. Therefore, &lt;code class=&quot;highlighter-rouge&quot;&gt;32 - x&lt;/code&gt; describes how many digits are dedicated to IP addresses inside this network. For example, the &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.0.0/16&lt;/code&gt; CIDR block can be translated to &lt;code class=&quot;highlighter-rouge&quot;&gt;00001010.00000001.xxxxxxxx.xxxxxxxx&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;As a rule, the &lt;code class=&quot;highlighter-rouge&quot;&gt;32 - x&lt;/code&gt; binary digits are set as zeros in CIDR notation, which is why a &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.1.0/16&lt;/code&gt; CIDR block would be impossible.&lt;/p&gt;

&lt;h3 id=&quot;network-sizes&quot;&gt;Network sizes&lt;/h3&gt;
&lt;p&gt;As you may have noticed, smaller &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt; values give larger networks, because a network has &lt;code class=&quot;highlighter-rouge&quot;&gt;2^(32-x)&lt;/code&gt; unique numbers inside it, each mapping to one IP address.&lt;/p&gt;

&lt;h3 id=&quot;subnets&quot;&gt;Subnets&lt;/h3&gt;
&lt;p&gt;Once I had figured this out, and created a VPC, I found my next problem - subnets. Subnets are subdivisions of the network they belong to, used to break networks down into smaller logical components, each dedicated to their own purpose, like hosting the database, running an API, etc. This can be useful for a host of reasons:&lt;/p&gt;

&lt;h5 id=&quot;security&quot;&gt;Security&lt;/h5&gt;
&lt;p&gt;With an understanding of which components communicate with which other components, subnets allowed me to set more fine-grained control over the flow of information inside my network. If the database has no reason to interact with our queueing system, then the database subnet can be set to not receive incoming or transmit outgoing traffic from the queue’s subnet.&lt;/p&gt;

&lt;h5 id=&quot;improve-network-performance&quot;&gt;Improve network performance&lt;/h5&gt;
&lt;p&gt;Given that all devices in a network has an entry point into it, each device must dedicate resources to filtering to only respond to requests meant for itself. Subnets have a more limited scope than their parent network, meaning that the total incoming traffic is reduced for each device, with an effect spread across all network devices.&lt;/p&gt;

&lt;h5 id=&quot;an-understanding-of-the-networks-growth&quot;&gt;An understanding of the network’s growth&lt;/h5&gt;
&lt;p&gt;Controlling the number of hosts available to each infrastructure component may be useful, in order to assign IP addresses to all your hosts necessary. You can dedicate a certain number of hosts to each subnet (depending on the size of the subnet mask), and leave room for each subnet to grow in the future.&lt;/p&gt;

&lt;h3 id=&quot;how-subnets-work&quot;&gt;How subnets work&lt;/h3&gt;
&lt;p&gt;If you want to split a &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.0.0/16&lt;/code&gt; network into subnets, you essentially only have &lt;code class=&quot;highlighter-rouge&quot;&gt;32 - x&lt;/code&gt; binary digits to allocate to these subnets, which in this case is &lt;code class=&quot;highlighter-rouge&quot;&gt;16&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;00000000.00000000&lt;/code&gt;. Just like with networks themselves, some of these digits will be dedicated to describing the subnet’s address, and the rest will be dedicated to the IP addresses in this subnet. Large subnets need many IP addresses, leaving fewer available for the subnet’s address. For example, if my subnet needs a maximum of 4 hosts, I only need 3 digits for that, so 13 can be dedicated to the subnet’s address, which could range between &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.0.0/3&lt;/code&gt; (&lt;code class=&quot;highlighter-rouge&quot;&gt;00001010.00000001.00000000.00000xxx&lt;/code&gt;), and &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.255.248/3&lt;/code&gt; (&lt;code class=&quot;highlighter-rouge&quot;&gt;00001010.00000001.11111111.11111xxx&lt;/code&gt;). Careful decisions around subnet addresses and subnet sizes allow users to “future-proof” their networks, allowing for scaling of a subnet, without other subnets getting in the way.
For a given subnet, its size is conventionally described using its “subnet mask”, which is the number you would get if all network address values were 1s. Therefore, &lt;code class=&quot;highlighter-rouge&quot;&gt;10.1.255.248/3&lt;/code&gt; would give 255.255.255.248&lt;/p&gt;

&lt;p&gt;I used Terraform’s &lt;a href=&quot;https://www.terraform.io/docs/configuration/functions/cidrsubnet.html&quot;&gt;cidrsubnet function&lt;/a&gt; to define my subnets. This function takes three arguments:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;prefix&lt;/code&gt;, the network’s CIDR block&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;newbits&lt;/code&gt;, the number by which to extend the prefix. The bigger this is, the smaller the subnet!&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;netnum&lt;/code&gt;, which determines the value of the newbits (the subnet’s address)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;individual-ip-addressesin-cidr-notation&quot;&gt;Individual IP addresses`in CIDR notation&lt;/h3&gt;
&lt;p&gt;When I needed to temporarily whitelist an IP address, I wasn’t sure how to do that, because AWS security groups and NACLs require inputs to use CIDR notation. The solution was very simple; as the number after the &lt;code class=&quot;highlighter-rouge&quot;&gt;/&lt;/code&gt; gets larger, the range of IP addresses gets smaller. Therefore, to limit this range to a single IP address, simply add the &lt;code class=&quot;highlighter-rouge&quot;&gt;/32&lt;/code&gt; suffix to the IP address, and your IP address will be converted into CIDR notation!&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;I still have lots to learn on networking, so if you identify any holes in my knowledge, or would like to start a conversation about this with me, then please reach out to me by email.&lt;/p&gt;</content><author><name>Jeroen Rijks</name></author><summary type="html">When I started working at Transreport, I was working with existing infrastructure, which other people had set in place for me. This let me get by without exposing me to a huge gap in my knowledge - networks, and how they work.</summary></entry><entry><title type="html">Sharing a filesystem between multiple Kubernetes workers</title><link href="http://localhost:4000/2020/04/12/shared_efs_volume.html" rel="alternate" type="text/html" title="Sharing a filesystem between multiple Kubernetes workers" /><published>2020-04-12T05:30:00+01:00</published><updated>2020-04-12T05:30:00+01:00</updated><id>http://localhost:4000/2020/04/12/shared_efs_volume</id><content type="html" xml:base="http://localhost:4000/2020/04/12/shared_efs_volume.html">&lt;h2 id=&quot;timeout-errors-and-asynchronous-jobs&quot;&gt;Timeout errors and asynchronous jobs&lt;/h2&gt;
&lt;p&gt;If a client sends a request to a server, and doesn’t receive a response for a long time, it will typically throw a timeout error. This marks the request as failed, and is done to stop users from waiting indefinitely. These timeout errors can happen for a variety of reasons, such as network infrastructure errors or bad error handling on the server side. Sometimes, this error is thrown when a perfectly valid request simply takes too long to process server-side.&lt;/p&gt;

&lt;p&gt;To cut down on timeout errors, compute-intensive tasks can be handled asynchronously. I’ve seen this implemented in two ways, and in both cases, it starts with a synchronous response to the request, effectively saying “We’ve received your request, it’s valid, and are dealing with it”.&lt;/p&gt;

&lt;h4 id=&quot;polling&quot;&gt;Polling&lt;/h4&gt;
&lt;p&gt;The last time I saw asynchronous PDF generation, the requester would then poll the server every second, asking if the PDF is ready yet. The server would give 2xx responses which would say “No, it’s not ready but keep asking me”, until the PDF was generated. The next polling request would receive the PDF as a response.&lt;/p&gt;

&lt;h4 id=&quot;websockets&quot;&gt;Websockets&lt;/h4&gt;
&lt;p&gt;The solution that’s being implemented now uses websockets. These open up a connection between the client and the server, allowing the server to send messages without receiving a request first. When the PDF is generated, the server sends a websocket “PDF is ready” message to the client. The client then sends an HTTPS request requesting the PDF, and the server responds synchronously.&lt;/p&gt;

&lt;h4 id=&quot;polling-vs-websockets&quot;&gt;Polling vs Websockets&lt;/h4&gt;
&lt;p&gt;Polling increases the total amount of network traffic, but the implementation I saw was used between two microservices running in the same Kubernetes cluster. Websockets require an open connection between clients and servers, and I don’t know whether this scales very well. Maybe it’ll be worth another post in the future.&lt;/p&gt;

&lt;h2 id=&quot;our-problem&quot;&gt;Our problem&lt;/h2&gt;
&lt;p&gt;To avoid timeout errors in Passenger Assist, Transreport have made our PDF reports asynchronous. This works great in local development, where one machine runs both Rails and Sidekiq. This is because the Rails application has access to the PDF generated by Sidekiq. However, in Kubernetes, Rails is run on different pods to Sidekiq, preventing the API from accessing the generated PDF.&lt;/p&gt;

&lt;p&gt;To solve this issue, a developer suggested writing PDFs to S3 in Sidekiq, and reading them from Rails. However, this would increase latency by sending requests all the way to the S3 API. Given the fact that Rails and Sidekiq are both running on the same Kubernetes cluster, this seems like a wasted opportunity. Therefore, I suggested mounting a volume into the worker nodes, to share the PDF between the processes locally. To solve this, I initially suggested that we could simply mount a directory from each EC2 instance straight into all Sidekiq and Rails pods running on it, but because the pods are spread across multiple workers, this would fail in cases where the cooperating Rails and Sidekiq pods weren’t running on the same machine. Therefore, I decided to use AWS EFS, a shared filesystem that can be mounted into all of our worker nodes, and then into all of our Sidekiq and Rails pods.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/premiumsupport/knowledge-center/eks-pods-efs/&quot;&gt;This AWS blog post&lt;/a&gt; offers a solution for managing EFS volumes in EKS clusters.&lt;/p&gt;

&lt;h4 id=&quot;solution-overview&quot;&gt;Solution overview&lt;/h4&gt;

&lt;p&gt;The solution creates a Kubernetes Persistent Volume Claim, which is available to other resources in the cluster (RBAC-permitting). An &lt;code class=&quot;highlighter-rouge&quot;&gt;efs-provisioner&lt;/code&gt; pod (using a Docker image provided by &lt;code class=&quot;highlighter-rouge&quot;&gt;quay.io&lt;/code&gt;) “supplies” this PVC with the EFS volume, so that any Kubernetes pod with access to the PVC can mount the EFS volume. This solution uses an existing EFS volume, so we’ll start with that.&lt;/p&gt;

&lt;h4 id=&quot;implementation---aws-side&quot;&gt;Implementation - AWS side&lt;/h4&gt;

&lt;p&gt;When working with unfamiliar tech, I usually get it to run manually first, and then import it into Terraform afterwards.&lt;/p&gt;

&lt;p&gt;First, I created a general purpose, bursting filesystem in the EFS console. After specifying the EFS type, I was prompted to create mount targets, which are used to grant access to the filesystem. Therefore, I created a mount target in each EKS subnet. After translating this to Terraform, it looks like this:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;resource &quot;aws_efs_file_system&quot; &quot;efs&quot; {
  creation_token    = &quot;&amp;lt;name&amp;gt;-${terraform.workspace}&quot;
  performance_mode  = &quot;generalPurpose&quot;
  throughput_mode   = &quot;bursting&quot;
  encrypted         = &quot;true&quot;
}

resource &quot;aws_efs_mount_target&quot; &quot;efs-mt&quot; {
  count = length(local.private_subnets[terraform.workspace])  # Create one mount target for each subnet
  file_system_id  = aws_efs_file_system.efs.id
  subnet_id = element(local.private_subnets[terraform.workspace], count.index)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, when I tried creating the efs-provisioner pod, it stalled at ContainerCreating, and its logs revealed that the volume was failing to mount into the container.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Warning FailedMount 1m kubelet, &amp;lt;ec2-instance-name&amp;gt; MountVolume.SetUp failed for volume &quot;pv-volume&quot; : mount failed: exit status 32
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Luckily, I’m not the first person to find this issue, and the internet told me that the mount targets need to allow inbound TCP connections on port 2049. After adding this to Terraform, my &lt;code class=&quot;highlighter-rouge&quot;&gt;efs.tf&lt;/code&gt; file looked like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;resource &quot;aws_efs_file_system&quot; &quot;efs&quot; {
  creation_token    = &quot;&amp;lt;name&amp;gt;-${terraform.workspace}&quot;
  performance_mode  = &quot;generalPurpose&quot;
  throughput_mode   = &quot;bursting&quot;
  encrypted         = &quot;true&quot;
}

resource &quot;aws_efs_mount_target&quot; &quot;efs-mt&quot; {
  count = length(local.private_subnets[terraform.workspace])  # Create one mount target for each subnet
  file_system_id  = aws_efs_file_system.efs.id
  subnet_id = element(local.private_subnets[terraform.workspace], count.index)
  security_groups = [aws_security_group.ingress_efs.id]
}

resource &quot;aws_security_group&quot; &quot;ingress_efs&quot; {
  name        = &quot;&amp;lt;name&amp;gt;-${terraform.workspace}-sg&quot;
  description = &quot;Allow EKS nodes to mount EFS storage volumes - Managed by Terraform&quot;
  vpc_id      = local.vpc_id[terraform.workspace]

  ingress {
    security_groups = [local.eks_security_group]
    from_port = 2049
    to_port = 2049
    protocol = &quot;tcp&quot;
  }

  egress {
    security_groups = [local.eks_security_group]
    from_port = 2049
    to_port = 2049
    protocol = &quot;tcp&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;implementation---kubernetes-side&quot;&gt;Implementation - Kubernetes Side&lt;/h4&gt;

&lt;p&gt;The AWS blog post summarises the Kubernetes implementation, which is pretty simple. To get separate EFS volumes for each environment, I defined the EFS ID in environment-specific values files, and passed these into the configmap:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// charts/pa-config/templates/efs_configmap.yaml
...
data:
  file.system.id: 
  aws.region: 
  provisioner.name: 
  dns.name: &quot;.efs..amazonaws.com&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;These values are called by the &lt;code class=&quot;highlighter-rouge&quot;&gt;efs_deployment.yaml&lt;/code&gt; file, which links the Terraform-managed EFS volume and the &lt;code class=&quot;highlighter-rouge&quot;&gt;efs_claim.yaml&lt;/code&gt; PVC.&lt;/p&gt;

&lt;p&gt;Finally, to mount this volume into my application pods, the pods mount the PVC:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;volumes:
- name: efs-pvc
  persistentVolumeClaim:
    claimName: &quot;efs-pa-&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and the pod containers mount the volume too:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;volumeMounts:
- name: efs-pvc
  mountPath: &quot;/&amp;lt;mount-path&amp;gt;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;Now, using &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl exec -it -n &amp;lt;namespace&amp;gt; &amp;lt;pod-name&amp;gt; &amp;lt;command&amp;gt;&lt;/code&gt;, we can test the solution. First, I created a file in the pod-defined mount path (&lt;code class=&quot;highlighter-rouge&quot;&gt;echo file_contents &amp;gt;&amp;gt; /&amp;lt;mount-path&amp;gt;/test_file&lt;/code&gt;) of the PDF-creating service. Then, &lt;code class=&quot;highlighter-rouge&quot;&gt;exec&lt;/code&gt;ing into the PDF-sending service, &lt;code class=&quot;highlighter-rouge&quot;&gt;ls /&amp;lt;mount-path&amp;gt;&lt;/code&gt; shows &lt;code class=&quot;highlighter-rouge&quot;&gt;test_file&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;cat /&amp;lt;mount-path&amp;gt;/test_file&lt;/code&gt; shows &lt;code class=&quot;highlighter-rouge&quot;&gt;file_contents&lt;/code&gt;. Pushing the new Helm charts to our Helm repository means that future releases will work for any environment, so long as &lt;code class=&quot;highlighter-rouge&quot;&gt;efs.enabled=true&lt;/code&gt;.&lt;/p&gt;</content><author><name>Jeroen Rijks</name></author><summary type="html">Timeout errors and asynchronous jobs If a client sends a request to a server, and doesn’t receive a response for a long time, it will typically throw a timeout error. This marks the request as failed, and is done to stop users from waiting indefinitely. These timeout errors can happen for a variety of reasons, such as network infrastructure errors or bad error handling on the server side. Sometimes, this error is thrown when a perfectly valid request simply takes too long to process server-side.</summary></entry><entry><title type="html">Implementing CloudFlare’s DDoS protection</title><link href="http://localhost:4000/2020/04/09/cloudflare-ddos-protection.html" rel="alternate" type="text/html" title="Implementing CloudFlare's DDoS protection" /><published>2020-04-09T05:30:00+01:00</published><updated>2020-04-09T05:30:00+01:00</updated><id>http://localhost:4000/2020/04/09/cloudflare-ddos-protection</id><content type="html" xml:base="http://localhost:4000/2020/04/09/cloudflare-ddos-protection.html">&lt;h3 id=&quot;the-stack&quot;&gt;The Stack&lt;/h3&gt;

&lt;p&gt;I had set up a website on AWS S3, and managing it using Terraform. In this blog post, I will discuss how I use CloudFlare for prepare my website for the real world. The objectives are to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Get my S3 website hosted on a public-facing domain managed in CloudFlare&lt;/li&gt;
  &lt;li&gt;Increase performance of my S3-hosted website&lt;/li&gt;
  &lt;li&gt;Increase security of my S3-hosted website&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The S3 bucket’s Terraform set-up is:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;resource &quot;aws_s3_bucket&quot; &quot;website&quot; {
  bucket        = local.bucket_name
  acl           = private
  region        = var.aws_region
  force_destroy = false

  website {
    index_document = &quot;index.html&quot;
    error_document = &quot;error.html&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;cloudflare&quot;&gt;CloudFlare&lt;/h2&gt;

&lt;p&gt;CloudFlare acts as a content delivery network, by caching web content in lots of geographical locations, speeding up response times by serving content that has been cached physically near the end user.&lt;/p&gt;

&lt;p&gt;CloudFlare also provides a firewall to monitor and filter your web traffic, based on CloudFlare-managed or self-managed rules. CloudFlare’s managed firewall rules are great because they are continuously updated using web traffic experienced by all of their clients. For example, if a CloudFlare client experiences a DDoS attack, where multiple malicious machines overload a web address with traffic (with the intent of preventing the website from serving normal users), these malicious IP addresses are added to an IP blacklist, and their requests are blocked for all CloudFlare firewall users.&lt;/p&gt;

&lt;h2 id=&quot;the-initial-solution&quot;&gt;The initial solution&lt;/h2&gt;
&lt;p&gt;I figured that creating a CNAME from my S3 URL to my CloudFlare domain would improve my website’s security with CloudFlare’s firewall.&lt;/p&gt;

&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;

&lt;p&gt;You may think that setting up an internet-facing URL (with a firewall) in CloudFlare would increase your S3-hosted website’s security, because all requests sent to the public-facing URL must make it through the firewall. However, CloudFlare is accessing the bucket contents via the bucket URL (bucket.s3-website.region.amazonaws.com), and so can anybody else. If malicious users were to discover the S3 bucket’s URL, they circumvent CloudFlare’s firewall and send requests directly to S3, and since there would be no CDN, DDoS attacks would be even easier.&lt;/p&gt;

&lt;h2 id=&quot;the-new-solution&quot;&gt;The new solution&lt;/h2&gt;

&lt;p&gt;To stop the S3 bucket from being publicly accessible, we want our S3 bucket policy to only give our developers and CI/CD product write access to the bucket, and only give CloudFlare can read from the bucket. This requires the following bucket configuration:&lt;/p&gt;

&lt;h3 id=&quot;public-access&quot;&gt;Public access&lt;/h3&gt;
&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;Block Public Access&lt;/code&gt; settings should be enabled fully, as shown in the following Terraform module.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;resource &quot;aws_s3_bucket_public_access_block&quot; &quot;website&quot; {
  bucket = aws_s3_bucket.website.id

  block_public_acls        = true
  block_public_policy      = true
  ignore_public_acls       = true
  restrict_public_buckets  = true
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;bucket-policy&quot;&gt;Bucket policy&lt;/h3&gt;
&lt;p&gt;The bucket policy will allow the &lt;code class=&quot;highlighter-rouge&quot;&gt;s3:GetObject&lt;/code&gt; action for all requests coming from CloudFlare’s IP addresses. We can limit successful requests using the bucket policy’s &lt;code class=&quot;highlighter-rouge&quot;&gt;IpAddress&lt;/code&gt; test, using CloudFlare’s Terraform provider to give us a big list of CloudFlare IPs.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;provider &quot;cloudflare&quot; {
  version = &quot;~&amp;gt; 2.0&quot;
}

data &quot;aws_iam_policy_document&quot; &quot;grant-cloudflare-ips&quot; {
  statement {
    sid = &quot;CloudflareIPsGetObject&quot;

    actions = [
      &quot;s3:GetObject&quot;
    ]

    effect = &quot;Allow&quot;

    resources = [
      &quot;arn:aws:s3:::${local.bucket_name}/*&quot;
    ]

    condition {
      test     = &quot;IpAddress&quot;
      variable = &quot;aws:SourceIp&quot;
      values   = concat(data.cloudflare_ip_ranges.cloudflare.ipv4_cidr_blocks, data.cloudflare_ip_ranges.cloudflare.ipv6_cidr_blocks)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: Our developers and CI pipeline grant appropriate permissions for the S3 bucket in the policies attached to their IAM groups. If you want all of your bucket policies kept in one place, then I’d suggest adding a &lt;code class=&quot;highlighter-rouge&quot;&gt;principals {...}&lt;/code&gt; section to your policy document.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, attach your policy to your bucket:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;resource &quot;aws_s3_bucket_policy&quot; &quot;static-bucket&quot; {
  bucket = aws_s3_bucket.website.id
  policy = data.aws_iam_policy_document.grant-cloudflare-ips-and-devs.json
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;cloudflare-cname&quot;&gt;CloudFlare CNAME&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;data &quot;cloudflare_zones&quot; &quot;zones&quot; {
  filter {
    name  = var.cloudflare_hosted_zone
  }
}

resource &quot;cloudflare_record&quot; &quot;cname&quot; {
  zone_id = data.cloudflare_zones.zones.zones[0].id
  name    = var.hostname  ## Set this to your desired subdomain
  type    = &quot;CNAME&quot;
  value   = &quot;s3-website.region.amazonaws.com&quot;  ## If your S3 bucket has a different name to your desired subdomain name, I'd suggest creating an alias to the bucket, and pointing your CNAME at that instead.
  ttl     = var.cloudflare_cname_ttl  ## This is up to you
  proxied = true
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;After applying all of the changes in Terraform, I tried to access the S3 URL, and my request was denied (as expected), since only CloudFlare’s IP addresses are whitelisted.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;img-fluid&quot; src=&quot;/assets/img/403_S3_cloudflare.png&quot; alt=&quot;403 error message from S3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However, accessing the CloudFlare-managed URL gave me access to the website right away.&lt;/p&gt;</content><author><name>Jeroen Rijks</name></author><summary type="html">The Stack</summary></entry><entry><title type="html">Kubectl Aliases</title><link href="http://localhost:4000/2020/03/26/kube-aliases.html" rel="alternate" type="text/html" title="Kubectl Aliases" /><published>2020-03-26T04:30:00+00:00</published><updated>2020-03-26T04:30:00+00:00</updated><id>http://localhost:4000/2020/03/26/kube-aliases</id><content type="html" xml:base="http://localhost:4000/2020/03/26/kube-aliases.html">&lt;p&gt;When I started at Transreport, I set up Helm charts for Passenger Assist, to make our deployments easier to set up. In hindsight, it was also a really good way to get to know the company’s products, because to set the Helm charts up, I needed a good understanding of the architecture, and what needs to happen for the program to run.&lt;/p&gt;

&lt;p&gt;Working with Kubernetes requires the use of &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl&lt;/code&gt;, a great command line tool that lets you interact with Kubernetes’ API. However, using &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl&lt;/code&gt; gets repetitive pretty quickly, especially if you’re working with namespaces; I regularly run commands like these:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;aws eks update-kubeconfig --name &amp;lt;passenger-assist-production-cluster-name&amp;gt;
kubectl get pods -n sqr-emr-staging
kubectl get pod -n pa-staging &amp;lt;pod-name&amp;gt; -o yaml
kubectl describe configmap -n sqr-emr-uat
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To save time, and to reduce the chance of making a typo, I’ve set up a few aliases, allowing me to replace those commands with:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kswitchprodpa
kgn po
kgyn po &amp;lt;pod-name&amp;gt;
kdn cm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;aliases&quot;&gt;Aliases&lt;/h3&gt;
&lt;p&gt;I (on my Ubuntu 18 OS) use aliases to speed my Kubernetes work up drastically. To avoid writing &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl&lt;/code&gt;, I added&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alias k='kubectl'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;to my &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.bashrc&lt;/code&gt; file. Every time I open a new terminal, it runs every line in my &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.bashrc&lt;/code&gt; file, which will now replace the letter &lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl&lt;/code&gt;, if I write it at the beginning of a command. Note that any already-open terminals won’t respond to changes in the &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.bashrc&lt;/code&gt; file, unless you run &lt;code class=&quot;highlighter-rouge&quot;&gt;source ~/.bashrc&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;simple-kubectl-aliases&quot;&gt;Simple kubectl aliases&lt;/h2&gt;
&lt;p&gt;Here are some standard &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl&lt;/code&gt; commands that I replaced:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alias k='kubectl'
alias ka='kubectl apply'
alias kl='kubectl logs'
alias ke='kubectl edit'
alias krm='kubectl delete'
alias kd='kubectl describe'
alias keit='kubectl exec -it'
alias kg='kubectl get'
alias kgsys='kubectl get -n kube-system'
alias wkg='watch kubectl get'
alias kgy='kubectl get -o yaml'
alias kwhere='kubectl config current-context'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;kubernetes-namespaces&quot;&gt;Kubernetes namespaces&lt;/h2&gt;
&lt;p&gt;Kubernetes uses namespaces to group resources together, and isolate them from other groups. &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl&lt;/code&gt; lets you select the namespace you’re interested in by adding &lt;code class=&quot;highlighter-rouge&quot;&gt;-n &amp;lt;namespace-name&amp;gt;&lt;/code&gt; to your &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl&lt;/code&gt; command. However, most of the time, you’ll need to run several commands in the same namespace, so adding &lt;code class=&quot;highlighter-rouge&quot;&gt;-n  &amp;lt;namespace-name&amp;gt;&lt;/code&gt; gets pretty tedious, especially when namespaces have long names. That’s why I’ve set up these aliases:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alias padev='KUBE_NAMESPACE=pa-dev'
alias pastaging='KUBE_NAMESPACE=pa-staging'
### There's a whole lot more of these
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alias kln='kubectl logs -n $KUBE_NAMESPACE'
alias ken='kubectl edit -n $KUBE_NAMESPACE'
alias krmn='kubectl delete -n $KUBE_NAMESPACE'
alias kdn='kubectl describe -n $KUBE_NAMESPACE'
alias keitn='kubectl exec -it -n $KUBE_NAMESPACE'
alias kgn='kubectl get -n $KUBE_NAMESPACE'
alias wkgn='watch kubectl get -n $KUBE_NAMESPACE'
alias kgyn='kubectl get -o yaml -n $KUBE_NAMESPACE'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, simply adding an &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt; to the end of my standard &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl&lt;/code&gt; shortcuts stops me from accidentally writing &lt;code class=&quot;highlighter-rouge&quot;&gt;-n pa-aut&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;-n sqr-emr=staging&lt;/code&gt; multiple times a day.&lt;/p&gt;

&lt;h2 id=&quot;switching-clusters&quot;&gt;Switching clusters&lt;/h2&gt;

&lt;p&gt;At Transreport, we use Terraform to create our EKS clusters, and to avoid naming clashes, their names have randomised strings at the ends. It’s annoying to have to learn them, so instead, I have these aliases set up:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alias kswitchnonprodpa='aws eks update-kubeconfig --name &amp;lt;name-of-eks-cluster&amp;gt;&amp;gt;'
alias kswitchprodpa='aws eks update-kubeconfig --name &amp;lt;name-of-eks-cluster&amp;gt;&amp;gt;'
alias kswitchnonprodcommon='aws eks update-kubeconfig --name &amp;lt;name-of-eks-cluster&amp;gt;&amp;gt;'
alias kswitchprodcommon='aws eks update-kubeconfig --name &amp;lt;name-of-eks-cluster&amp;gt;&amp;gt;'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;helm&quot;&gt;Helm&lt;/h2&gt;
&lt;p&gt;Helm is essentially a Kubernetes package manager, and its command line tool, &lt;code class=&quot;highlighter-rouge&quot;&gt;helm&lt;/code&gt;, works pretty similarly to &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl&lt;/code&gt;, in terms of using namespaces. Use the same trick:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alias helmn='helm -n $KUBE_NAMESPACE`
alias helmlsn='helm ls -n $KUBE_NAMESPACE`
alias helmgvn='helm get values -n $KUBE_NAMESPACE`
alias helmtp='helm template --output-dir .`
alias helmtpn='helm template --output-dir . -n $KUBE_NAMESPACE`
alias helmsearch='helm search repo'  ### Avoid getting it wrong and typing helm repo search every time.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Other helm commands like &lt;code class=&quot;highlighter-rouge&quot;&gt;helm install&lt;/code&gt; probably deserve the time taken to type the command out.&lt;/p&gt;

&lt;h3 id=&quot;side-note-for-terraform-users&quot;&gt;Side note for Terraform users&lt;/h3&gt;

&lt;p&gt;Do yourself a favour and never write &lt;code class=&quot;highlighter-rouge&quot;&gt;terrafrom&lt;/code&gt; again:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alias tf='terraform'
alias tfi='terraform init'
alias tfws='terraform workspace'
alias tfwsl='terraform workspace list'
alias tfs='terraform state'
alias tfsl='terraform state list'
alias tfp='terraform plan'
alias tfa='terraform apply'
alias tfaa='terraform apply -auto-approve'   --&amp;gt; Don't use this unless you're a #madlad
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Jeroen Rijks</name></author><summary type="html">When I started at Transreport, I set up Helm charts for Passenger Assist, to make our deployments easier to set up. In hindsight, it was also a really good way to get to know the company’s products, because to set the Helm charts up, I needed a good understanding of the architecture, and what needs to happen for the program to run.</summary></entry><entry><title type="html">How I started my career</title><link href="http://localhost:4000/2020/03/01/starting-my-career.html" rel="alternate" type="text/html" title="How I started my career" /><published>2020-03-01T14:52:13+00:00</published><updated>2020-03-01T14:52:13+00:00</updated><id>http://localhost:4000/2020/03/01/starting-my-career</id><content type="html" xml:base="http://localhost:4000/2020/03/01/starting-my-career.html">&lt;p&gt;I started my career as a backend developer for a technical consultancy called &lt;a href=&quot;https://www.solirius.com&quot;&gt;Solirius Consulting&lt;/a&gt;. After a year of learning on the job, supplemented with dedicated learning in a supportive environment, I built up enough experience with Java, Python, and various DevOps tools, to call myself a competent software engineer. However, the most important things that I learned at Solirius are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the importance of good communication skills&lt;/li&gt;
  &lt;li&gt;an understanding of how to work with other people&lt;/li&gt;
  &lt;li&gt;what I want my career to look like&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;solirius&quot;&gt;Solirius&lt;/h3&gt;
&lt;p&gt;At Solirius, I worked on the &lt;a href=&quot;https://www.gov.uk/guidance/the-hmcts-reform-programme&quot;&gt;digitalisation of the Ministry of Justice&lt;/a&gt;, which was a large-scale project, in which our microservice team provided utility APIs to approximately 10 other microservice teams. A centralised platform engineering team provided a platform for each microservice to deploy onto, and was following the industry-wide trend to host microservices on Kubernetes. Given a lot of freedom to select my own tasks, I chose to set up our Kubernetes manifests, and subsequently learnt my way around Kubernetes, Helm, Azure and Jenkins.&lt;/p&gt;

&lt;p&gt;After learning more about DevOps, I realised that despite spending so much time with Kubernetes, I still didn’t feel like I had any ownership of what I had created. It was this, combined with the desire to become a Kubernetes god, that made me decide to leave Solirius, in pursuit of a career in DevOps.&lt;/p&gt;

&lt;h3 id=&quot;transreport&quot;&gt;Transreport&lt;/h3&gt;
&lt;p&gt;In September 2019, I joined &lt;a href=&quot;http://www.transreport.co.uk&quot;&gt;Transreport&lt;/a&gt;, a small startup working on an awesome product, Passenger Assist. Working with some amazing people in our London, Glasgow and Romanian offices, we have created a system that will help rail companies to provide assistance to disabled travellers throughout the UK.&lt;/p&gt;

&lt;p&gt;Simply put, my responsibility is to make sure that the docker images I’m given run successfully, prioritising reliability, security, and scalability. I’m now also realising that a better understanding of coding will lead to a better proficiency in DevOps, so there might be some Ruby, Python, or other stuff in there too.&lt;/p&gt;</content><author><name>Jeroen Rijks</name></author><summary type="html">I started my career as a backend developer for a technical consultancy called Solirius Consulting. After a year of learning on the job, supplemented with dedicated learning in a supportive environment, I built up enough experience with Java, Python, and various DevOps tools, to call myself a competent software engineer. However, the most important things that I learned at Solirius are: the importance of good communication skills an understanding of how to work with other people what I want my career to look like</summary></entry></feed>